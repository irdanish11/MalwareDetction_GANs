# -*- coding: utf-8 -*-
"""
Created on Tue Sep  1 17:28:57 2020

@author: Danish
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, BatchNormalization, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from BatchGenerator import BatchGenerator
import numpy as np
from utilities import PrintInline, Timer, info_out, Callbacks
import os

def create_generator(input_shape, name):
    with tf.name_scope(name):
        gen_input = Input(input_shape)
        
        d1 = Dense(input_shape)(gen_input)
        lr1 = LeakyReLU(0.2)(d1)
        
        d2 = Dense(input_shape//2)(lr1)
        lr2 = LeakyReLU(0.2)(d2)
        
        d3 = Dense(input_shape)(lr2)
        lr3 = LeakyReLU(0.2)(d3)
        
        generator = Model(inputs=gen_input, outputs=lr3, name=name)
    
    return generator

def create_discriminator(input_shape, opt, name):
    with tf.name_scope(name):
        disc_input = Input(input_shape)
        
        d1 = Dense(input_shape)(disc_input)
        lr1 = LeakyReLU(0.2)(d1)
        
        d2 = Dense(input_shape//4)(lr1)
        lr2 = LeakyReLU(0.2)(d2)
        
        d3 = Dense(input_shape//16)(lr2)
        lr3 = LeakyReLU(0.2)(d3)
        
        fc = Dense(1, activation='sigmoid')(lr3)
        
        discriminator = Model(inputs=disc_input, outputs=fc, name=name)
        discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
    return discriminator

def create_gan(input_shape, opt, name, summary=True):
    generator = create_generator(input_shape, name='Geneartor')
    discriminator = create_discriminator(input_shape, opt, name='Discriminator')
    #Make the discriminator untrainable when we are training the generator.  
    #This doesn't effect the discriminator by itself
    discriminator.trainable = False
    #Combine the two models to create the GAN
    gan_input = Input(shape=input_shape)
    fake_data = generator(gan_input)
    gan_output = discriminator(fake_data)
    
    gan = Model(gan_input, gan_output, name=name)
    #No model compilation because training is done using GradientTape
    gan.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
    if summary:
        discriminator.summary()
        gan.summary()
    return generator, discriminator, gan

def train_gan(X, epochs=2, batch_size=32):  
    
    X_goodware = X[0] 
    X_malware = X[1]
    
    #Creating Models
    input_shape = X_malware.shape[1]
    opt = Adam(learning_rate=0.001)
    generator, discriminator, gan = create_gan(input_shape, opt, name='GAN')
    
    #creating callback for saving checkpoints
    cb = Callbacks(ckpt_path='./checkpoints', models=[generator, discriminator, gan])
    
    steps_per_epoch = X_malware.shape[0]//batch_size
    batches = []
    history_epochs = {'Disc_Loss':[], 'Disc_Acc':[], 'Gen_Loss':[], 'Gen_Acc':[], 'Batch_Data':[]}
    for epoch in range(1, epochs+1):
        time =Timer()
        history_batch = {'Disc_Loss':[], 'Disc_Acc':[], 'Gen_Loss':[], 'Gen_Acc':[], 'Batch_Data':[]}
        bg = BatchGenerator(X_malware, batch_size, batch_shape=None)
        for batch in range(1, steps_per_epoch+1):
            #Getting next batch
            batch_malware = bg.get_nextBatch()
            #generating features from Generator
            gen_features = generator.predict(batch_malware)
            #getting samples from goodware for concatenation
            batch_goodware = X_goodware[np.random.randint(0, X_goodware.shape[0], size=batch_size)]
            #converting sparse to dense
            batch_goodware = batch_goodware.todense()
            #Concatenating Goodware and generated features.
            x = np.concatenate((batch_goodware, gen_features))
            #Generating labels for x
            disc_y = np.zeros(2*batch_size)
            disc_y[:batch_size] = 1.0
            
            #Train Discriminator
            disc_metric = discriminator.train_on_batch(x, disc_y)
            history_batch['Disc_Loss'].append(disc_metric[0])
            history_batch['Disc_Acc'].append(disc_metric[1])
            
            #Train Generator using GAN model
            y_gen = np.ones(batch_size)
            gen_metric = gan.train_on_batch(batch_malware, y_gen)
            history_batch['Gen_Loss'].append(gen_metric[0])
            history_batch['Gen_Acc'].append(gen_metric[1])
            
            #Printing info of batch
            time_remain, time_taken = time.get_time_hhmmss(steps_per_epoch-batch)
            timers = (time_remain, time_taken) 
            history = (history_batch, history_epochs)
            info_out('batch', history, timers, epoch, epochs, batch, steps_per_epoch)
            
            #computing loss & accuracy over one epoch
            history_epochs['Disc_Loss'].append(sum(history_batch['Disc_Loss'])/steps_per_epoch)
            history_epochs['Disc_Acc'].append(sum(history_batch['Disc_Acc'])/steps_per_epoch)
            history_epochs['Gen_Loss'].append(sum(history_batch['Gen_Loss'])/steps_per_epoch)
            history_epochs['Gen_Acc'].append(sum(history_batch['Gen_Acc'])/steps_per_epoch)
            history_epochs['Batch_Data'].append(history_batch)
            info_out(which='epoch', epoch=epoch, total_time=time.get_total_time())
            cb.ckpt_callback(epoch, history_epochs)
            
            
            

            
    