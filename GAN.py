# -*- coding: utf-8 -*-
"""
Created on Tue Sep  1 17:28:57 2020

@author: Danish
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, ReLU, Input, LeakyReLU
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.optimizers import Adam
from BatchGenerator import BatchGenerator
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import classification_report 
from utilities import Timer, info_out, Callbacks, plot_confusion_matrix
from tensorflow.keras.utils import plot_model 
from pickle import dump
import numpy as np
import os
import scipy
from tqdm import tqdm
import json

def Step(x): 
    threshold=0.5
    comparison = tf.greater(x, tf.constant(threshold))    
    x = tf.where (comparison, tf.ones_like(x), x)
    
    comparison = tf.less_equal(x, tf.constant(threshold))    
    x = tf.where (comparison, tf.zeros_like(x), x)
    return x

def create_generator(input_shape, name):
    with tf.name_scope(name):
        gen_input = Input(input_shape)
        
        d1 = Dense(1024)(gen_input)
        lr1 = LeakyReLU(0.2)(d1)
        
        d2 = Dense(512)(lr1)
        lr2 = LeakyReLU(0.2)(d2)
        
        d3 = Dense(input_shape)(lr2)
        lr3 = ReLU()(d3)
        
        generator = Model(inputs=gen_input, outputs=lr3, name=name)
    
    return generator

def create_discriminator(input_shape, opt, name):
    with tf.name_scope(name):
        disc_input = Input(input_shape)
        
        d1 = Dense(256)(disc_input)
        lr1 = LeakyReLU(0.2)(d1)
        
        d2 = Dense(128)(lr1)
        lr2 = LeakyReLU(0.2)(d2)
        
        # d3 = Dense(256)(lr2)
        # lr3 = ReLU()(d3)
        
        fc = Dense(1, activation='sigmoid')(lr2)
        
        discriminator = Model(inputs=disc_input, outputs=fc, name=name)
        discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
    return discriminator

def create_gan(input_shape, path, opt, name, summary=True):
    generator = create_generator(input_shape, name='Geneartor')
    discriminator = create_discriminator(input_shape, opt, name='Discriminator')
    #Make the discriminator untrainable when we are training the generator.  
    #This doesn't effect the discriminator by itself
    discriminator.trainable = False
    #Combine the two models to create the GAN
    gan_input = Input(shape=input_shape)
    fake_data = generator(gan_input)
    gan_output = discriminator(fake_data)
    
    gan = Model(gan_input, gan_output, name=name)
    #No model compilation because training is done using GradientTape
    gan.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
    if summary:
        generator.summary()
        print('\n')
        discriminator.summary()
        print('\n')
        gan.summary()
        os.makedirs(path, exist_ok=True)
        plot_model(generator, to_file=path+'Generator.png', show_shapes=True, dpi=300)
        plot_model(discriminator, to_file=path+'Discriminator.png', show_shapes=True, dpi=300)
        plot_model(gan, to_file=path+'GAN.png', show_shapes=True, expand_nested=True, dpi=300)
    return generator, discriminator, gan

def shuffle(arr):
    return arr[np.random.randint(0, arr.shape[0], size=arr.shape[0])]    
    
def train_gan(X, path, epochs=2, batch_size=64): 
    if path[-1] != '/':
        path += '/'
    os.makedirs(path+'checkpoints', exist_ok=True)
    
    X_benignware = X[0] 
    X_malware = X[1]
    
    #Creating Models
    input_shape = X_malware.shape[1]
    opt = Adam(learning_rate=0.001)
    generator, discriminator, gan = create_gan(input_shape, path, opt, name='GAN')
    
    #creating callback for saving checkpoints
    cb = Callbacks(ckpt_path=path+'checkpoints', models=[generator, discriminator, gan])
    
    steps_per_epoch = X_malware.shape[0]//batch_size
    history_epochs = {'Disc_Loss':[], 'Disc_Acc':[], 'Gen_Loss':[], 'Gen_Acc':[], 'Batch_Data':[]}
    
    chk = input('\n\nStart training GANs (y/N): ')
    if chk.lower()=='y':
        for epoch in range(1, epochs+1):
            time =Timer()
            history_batch = {'Disc_Loss':[], 'Disc_Acc':[], 'Gen_Loss':[], 'Gen_Acc':[], 'Batch_Data':[]}
            bg = BatchGenerator(X_malware, batch_size, batch_shape=None)
            for batch in range(1, steps_per_epoch+1):
                #start the timer
                time.start()
                #Getting next batch
                batch_malware = bg.get_nextBatch()
                #generating features from Generator
                gen_features = generator.predict(batch_malware)
                #getting samples from benignware for concatenation
                batch_benignware = X_benignware[np.random.randint(0, X_benignware.shape[0], size=batch_size)]
                #converting sparse to dense
                batch_benignware = batch_benignware.todense()
                
                # #Concatenating Benignware and generated features.
                # x = np.concatenate((batch_benignware, gen_features))
                
                #Generating labels for x
                #disc_y = np.zeros(2*batch_size)
                # disc_y[:batch_size] = 1.0
                
                #Train Discriminator
                #disc_metric = discriminator.train_on_batch(x, disc_y)
                
                #Generating labels for x
                disc_y = np.full(batch_size, 0)
                #Train Discriminator
                disc_metric0 = discriminator.train_on_batch(gen_features, disc_y)
                #Generating labels for x
                disc_y = np.full(batch_size, 1)
                #Train Discriminator
                disc_metric1 = discriminator.train_on_batch(batch_benignware, disc_y)
                disc_metric = [(disc_metric0[0]+disc_metric1[0])/2, 
                               (disc_metric0[1]+disc_metric1[1])/2]
                
                
                history_batch['Disc_Loss'].append(disc_metric[0])
                history_batch['Disc_Acc'].append(disc_metric[1])
                
                #Train Generator using GAN model
                y_gen = np.ones(batch_size)
                gen_metric = gan.train_on_batch(batch_malware, y_gen)
                gen_metric = gan.train_on_batch(batch_malware, y_gen)
                gen_metric = gan.train_on_batch(batch_malware, y_gen)
                gen_metric = gan.train_on_batch(batch_malware, y_gen)
                gen_metric = gan.train_on_batch(batch_malware, y_gen)
                history_batch['Gen_Loss'].append(gen_metric[0])
                history_batch['Gen_Acc'].append(gen_metric[1])
                
                #Printing info of batch
                time_remain, time_taken = time.get_time_hhmmss(steps_per_epoch-batch)
                timers = (time_remain, time_taken) 
                history = (history_batch, history_epochs)
                info_out('batch', history, timers, epoch, epochs, batch, steps_per_epoch)
                
            #computing loss & accuracy over one epoch
            history_epochs['Disc_Loss'].append(sum(history_batch['Disc_Loss'])/steps_per_epoch)
            history_epochs['Disc_Acc'].append(sum(history_batch['Disc_Acc'])/steps_per_epoch)
            history_epochs['Gen_Loss'].append(sum(history_batch['Gen_Loss'])/steps_per_epoch)
            history_epochs['Gen_Acc'].append(sum(history_batch['Gen_Acc'])/steps_per_epoch)
            history_epochs['Batch_Data'].append(history_batch)
            
            history = (history_batch, history_epochs)
            info_out(which='epoch', history=history, epoch=epoch, total_time=time.get_total_time())
            cb.ckpt_callback(epoch, history_epochs)
    elif chk.lower()=='n':
        SystemExit
    #Writing history to disk
    dump(history_epochs, open(path+'checkpoints/history.obj', 'wb'))
    return history_epochs
            
def get_acc(Y, Y_pred, labels):
    #Computing Accuracy
    acc = accuracy_score(Y, Y_pred)
    print('\nDiscriminator Classification Accuracy: {0:.4f}'.format(acc))
    #Getting Classification Report
    keys = list(labels.keys())
    values =list(labels.values())
    report = classification_report(Y, Y_pred, labels=keys, target_names=values)
    print("\nDiscriminator Classification Report:\n", report)
    return acc, values

def evaluate_discriminator(X_test, labels, gans_path, path_cm, title, normalize='all'):
    print('\n___________________________________________________________________________')
    print('Evaluating Discriminator...\n')
    #loading Discriminator model
    if gans_path[-1]!='/':
        gans_path += '/'
    discriminator = load_model(gans_path+'Discriminator.h5')
    generator = load_model(gans_path+'Generator.h5')
    
    #Preparing data
    X_benignware = X_test[0].todense()
    X_malware = X_test[1].todense()

    #Getting predictions from Generator
    X_generated = generator.predict(X_malware)
    len_gen = X_generated.shape[0]
    
    #Preparing X_real, Y_real & Y_generated
    X_real = X_benignware
    len_real = X_real.shape[0]
    Y_real = np.zeros(len_real)
    Y_generated = np.ones(len_gen)
    
    #Making predictions on Discriminator
    Y_pred_real = discriminator.predict(X_real)
    Y_pred_gen =  discriminator.predict(X_generated)   
    
    Y_pred = np.concatenate((Y_pred_real, Y_pred_gen))
    Y_pred = np.where(Y_pred>0.5, 1, 0)
    Y = np.array(np.concatenate((Y_real, Y_generated)))
    
    acc, values = get_acc(Y, Y_pred, labels)
    #Get and plot Confusion matrix
    cm_n = confusion_matrix(Y, Y_pred, normalize=normalize)
    cm = confusion_matrix(Y, Y_pred)
    if '.png' not in path_cm:
        path_cm += '.png'
    path_n = path_cm.split('.png')[0]+'_Normalised.png'
    plot_confusion_matrix(cm, values, path_cm, title)
    plot_confusion_matrix(cm_n, values, path_n, title)
    print('\nEvaluation of Discriminator is Completed!')
    print('___________________________________________________________________________\n')
    return acc

    

def generate_features(X_malware, feature_names, gans_path, save_path):  
    features_path = save_path+'Features/'
    os.makedirs(features_path, exist_ok=True)
    if gans_path[-1]!='/':
        gans_path += '/'
    generator = load_model(gans_path+'Generator.h5')
    if type(X_malware) == scipy.sparse.csr.csr_matrix:
        X_malware = X_malware.todense()
    gen_features = generator.predict(X_malware)
    feature_names = np.array(feature_names)
    sample_features = feature_names.reshape(1,feature_names.shape[0])
    for i, sample in enumerate(tqdm(gen_features)):
        indicies = shuffle(np.where(sample==0)[0])
        sample_features = list(feature_names[indicies])
        with open(features_path+'GeneratedFeatures_{0}.json'.format(i+1), 'w') as f:
            json.dump(sample_features, f)
    return sample_features, gen_features
    